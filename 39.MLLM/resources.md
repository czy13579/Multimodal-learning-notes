### 1.multimodal-LLM-study
https://github.com/yangminghuan/multimodal-LLM-study/tree/main

### 2.从头开始构建自己的多模态大型模型
https://github.com/xinyanghuang7/Basic-Visual-Language-Model

### 3.微调多模态大模型
https://github.com/BUAADreamer/MLLM-Finetuning-Demo

### 4.开源多模态大模型
https://github.com/Jacksonlark/open-mllms

### 5.资源库
https://github.com/Atomic-man007/Awesome_Multimodel_LLMs
https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models

### 6.综述
https://ar5iv.labs.arxiv.org/html/2309.10020?_immersive_translate_auto_translate=1

### 7.Multimodal-LLM论文汇总
https://mm-llms.github.io/categories/arxiv/

### 8.视觉大模型综述
https://blog.csdn.net/CV_Autobot/article/details/132179258
## models
### 1.BLIP
**详细的介绍：** https://www.cvmart.net/community/detail/7740/
**论文**：https://larxiv.org/pdf/2201.12086.pdf
**code:**
https://github.com/salesforce/BLIP
**code-hf:** https://github1s.com/huggingface/transformers/blob/main/src/transformers/models/blip/modeling_blip.py


### 2.BLIP2
**详细的介绍：** https://www.cvmart.net/community/detail/7768/
**论文：** https://arxiv.org/pdf/2301.12597.pdf
**code:**
https://github.com/salesforce/LAVIS/tree/main/projects/blip2
**code-hf:** https://github1s.com/huggingface/transformers/blob/main/src/transformers/models/blip2/modeling_blip2.py
**BLIP2微调：** https://github.com/liguodongiot/llm-action/tree/main/llm-train/peft/multimodal


### 3.visionGPT
**论文：** https://arxiv.org/abs/2102.10407
**code:** https://github.com/Vision-CAIR/VisualGPT


### 4.ViperGPT
**论文：** https://arxiv.org/abs/2303.08128
**code:** https://github.com/cvlab-columbia/viper
**pronpt:** https://github.com/cvlab-columbia/viper/blob/main/prompts/benchmarks/nextqa.prompt
**demo:** 
**csdn blog:** https://blog.csdn.net/m0_56661101/article/details/131661458

### 5.miniGPT4
**论文：** https://arxiv.org/abs/2304.10592
**code:** https://github.com/Vision-CAIR/MiniGPT-4
**csdn blog:** https://blog.csdn.net/qq_37261357/article/details/137354958
**colab demo:** https://github.com/Czi24/Awesome-MLLM-LLM-Colab/tree/master/MLLM/MiniGPT-4-colab
**demo hf:** https://huggingface.co/spaces/Vision-CAIR/minigpt4

### 6.miniGPT-v2
**论文：** https://arxiv.org/abs/2310.09478
**code:** https://github.com/Vision-CAIR/MiniGPT-4
**demo hf:** https://huggingface.co/spaces/Vision-CAIR/MiniGPT-v2

### 7.TinyGPT-V
**论文：** https://arxiv.org/abs/2312.16862
**code:** https://github.com/DLYuanGod/TinyGPT-V


### 8.ChatCaptioner
**论文：** https://arxiv.org/abs/2303.06594
**code:** https://github.com/Vision-CAIR/ChatCaptioner

### 9.ImageBind
**论文：** https://arxiv.org/abs/2305.05665
**code:** https://github.com/facebookresearch/ImageBind

### 10.LLaVA
**论文：** https://arxiv.org/abs/2304.08485
**code:** https://github.com/haotian-liu/LLaVA
**LLaVA系列 csdn blog:** https://blog.csdn.net/2401_84033492/article/details/139381898

### 11.LLaVA 1.5
**论文：** https://arxiv.org/abs/2310.03744
**code:** https://github.com/haotian-liu/LLaVA
**LLaVA phi论文：** https://arxiv.org/abs/2401.02330
**MoE-LLaVA论文：** https://arxiv.org/abs/2401.15947
**VILA论文：** https://arxiv.org/abs/2312.07533

### 12.LLaVA-Next
**blog-2024-01-30:** https://llava-vl.github.io/blog/2024-01-30-llava-next/
**blog-2024-05-10:** https://llava-vl.github.io/blog/2024-05-10-llava-next-stronger-llms/
**code:** https://github.com/LLaVA-VL/LLaVA-NeXT

### 13.TinyLLaVA
**论文：** https://arxiv.org/abs/2402.14289
**code:** https://github.com/TinyLLaVA/TinyLLaVA_Factory

### 14.Qwen-VL
**论文：** https://arxiv.org/abs/2308.12966
**code:** https://github.com/qwenlm/qwen-vl

### 15.PaLI-3
**PaLI-1:** https://arxiv.org/abs/2209.06794
**论文：** https://arxiv.org/abs/2310.09199
**PaLIGemma:** https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/README.md

### 16.GiT
**论文：** https://arxiv.org/abs/2205.14100
**code:** https://github.com/microsoft/GenerativeImage2Text





